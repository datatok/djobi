executor:
  type: spark
  spec:
    cluster:
      type: local
    driver:
      cpu: 1
      memory: 4Gb
    workers:
      num: 2
      cpus: 2
      memory: 10Gb
parameters:
  date:
    type: daily_date
  pp: pp
  pd: pipeline
jobs:
  job1:
    parameters:
      p1: p1
      p2: p2
      pd: job
    matrix:
      a:
        pjc1: a
        pd: context_a
        label_field: title
        file: exists
      b:
        pjc2: b
        pd: context_b
        file: not_found
    stages:
      - name: setup_file
        kind: fs-input
        spec:
          path: "../data/json_1"
          format: json
      - name: as_table
        kind: org.spark.mutate
        spec:
          alias_table: my_json_1
      - name: input
        kind: "sql"
        check: false
        spec:
          query: "queries/{{pd}}.sql"
      - name: filter
        kind: "org.spark.mutate"
        spec:
          adds:
            day: "{{day}}\\/{{month}}\\/{{year}}"
      - name: output
        kind: "fs-output"
        spec:
          path: "/tmp/djobi_test_engine"
          options:
            mode: overwrite
