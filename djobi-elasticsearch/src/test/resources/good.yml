executor:
  type: spark
  spec:
    cluster:
      type: local
    driver:
      cpu: 1
      memory: 4Gb
    workers:
      num: 2
      cpus: 2
      memory: 10Gb
parameters:
  date:
    type: daily_date
  pp: pp
  pd: pipeline
jobs:
  job1:
    parameters:
      p1: p1
      p2: p2
      pd: job
    contexts:
      a:
        pjc1: a
        pd: context_a
        label_field: title
        file: exists
      b:
        pjc2: b
        pd: context_b
        file: not_found
    stages:
      setup_file:
        kind: fs-input
        spec:
          path: "./json_1"
          format: json
      as_table:
        kind: org.spark.mutate
        spec:
          alias_table: my_json_1
      input:
        kind: sql
        check: false
        spec:
          query: "queries/{{pd}}.sql"
      filter:
        kind: "org.spark.mutate"
        spec:
          adds:
            day: "{{day}}\\/{{month}}\\/{{year}}"
      output:
        kind: org.elasticsearch.output
        spec:
          host: "{{env.elasticsearch}}"
          index: "out-{{pd}}/all"
          clean_query: "day:{{day}}\\/{{month}}\\/{{year}}"
